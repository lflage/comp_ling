{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from my_lda import LDA\n",
    "import corpus_man as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(df):\n",
    "    confusion_matrix = pd.DataFrame(0,\n",
    "                                    index=['arcmed','mod','cont'],\n",
    "                                    columns=range(len(df['predicted_period'].unique())))\n",
    "    for index in range(len(df)):\n",
    "        initial = df['period'][index]\n",
    "        predicted = df['predicted_period'][index]\n",
    "        confusion_matrix[predicted][initial] += 1\n",
    "        \n",
    "    return confusion_matrix\n",
    "\n",
    "def removeMime(to_slice):\n",
    "    return to_slice[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading tycho XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate http://www.tycho.iel.unicamp.br/corpus/texts/xml.zip -P ./corpora\n",
    "!mkdir ./corpora/xml\n",
    "!unzip ./corpora/xml.zip -d ./corpora/xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSV Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cont      48\n",
       "mod       28\n",
       "arcmed    13\n",
       "Name: period, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('periodos_tycho.csv',header=None)\n",
    "df.columns = ['period', 'file_name']\n",
    "df['genre'] = None\n",
    "df['predicted_period'] = None\n",
    "\n",
    "cond1 = df.period =='cont2'\n",
    "df['period'] = df['period'].replace(['cont1'],'cont')\n",
    "df['period'] = df['period'].replace(['cont2'],'cont')\n",
    "\n",
    "\n",
    "df.period.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_name'] = df['file_name'].apply(removeMime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>file_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>predicted_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arcmed</td>\n",
       "      <td>l_002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcmed</td>\n",
       "      <td>g_009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arcmed</td>\n",
       "      <td>p_002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arcmed</td>\n",
       "      <td>b_002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arcmed</td>\n",
       "      <td>m_007</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   period file_name genre predicted_period\n",
       "0  arcmed     l_002  None             None\n",
       "1  arcmed     g_009  None             None\n",
       "2  arcmed     p_002  None             None\n",
       "3  arcmed     b_002  None             None\n",
       "4  arcmed     m_007  None             None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.sort_values(by='file_name').reset_index().drop('index',axis=1)\n",
    "new_df = new_df.set_index('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every xml file is parsed and the corresponding xml file is stored as\n",
    "# a key value pair in the forest dict, where the key is the file name\n",
    "# and the value is the parsed xml file\n",
    "\n",
    "forest={}\n",
    "for root, dirs, files in os.walk(\"./corpora/xml\", topdown=False):\n",
    "    for file_name in sorted(files):\n",
    "        with open(os.path.join(root,file_name),'r') as xml:\n",
    "            xml_plain = '\\n'.join(xml.read().split('\\n')[1:])\n",
    "            try:\n",
    "                forest[file_name] = etree.fromstring(xml_plain)\n",
    "            except etree.XMLSyntaxError as error:\n",
    "                print(error)\n",
    "                print(xml_plain)\n",
    "            except ValueError:\n",
    "                print(xml_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_001.xml----a_001.xml\n",
      "a_002.xml----a_002.xml\n",
      "a_003.xml----a_003.xml\n",
      "a_004.xml----a_004.xml\n",
      "a_005.xml----a_005.xml\n",
      "a_006.xml----a_006.xml\n",
      "a_007.xml----a_007.xml\n",
      "a_008.xml----a_008.xml\n",
      "a_009.xml----a_009.xml\n",
      "b_001.xml----b_001.xml\n",
      "b_002.xml----b_002.xml\n",
      "b_003.xml----b_003.xml\n",
      "b_005.xml----b_005.xml\n",
      "b_006.xml----b_006.xml\n",
      "b_007.xml----b_007.xml\n",
      "b_008.xml----b_008.xml\n",
      "b_009.xml----b_009.xml\n",
      "b_010.xml----b_010.xml\n",
      "b_011.xml----b_011.xml\n",
      "c_001.xml----c_001.xml\n",
      "c_002.xml----c_002.xml\n",
      "c_003.xml----c_003.xml\n",
      "c_004.xml----c_004.xml\n",
      "c_005.xml----c_005.xml\n",
      "c_006.xml----c_006.xml\n",
      "c_007.xml----c_007.xml\n",
      "c_008.xml----c_008.xml\n",
      "c_009.xml----morgadinha-valflor-final.xml\n",
      "c_010.xml----c_010.xml\n",
      "d_001.xml----d_001.xml\n",
      "e_001.xml----e_001.xml\n",
      "f_001.xml----f_001.xml\n",
      "f_002.xml----f_002.xml\n",
      "f_003.xml----f_003.xml\n",
      "g_001.xml----g_001.xml\n",
      "g_002.xml----g_002.xml\n",
      "g_003.xml----g_003.xml\n",
      "g_004.xml----g_004.xml\n",
      "g_005.xml----g_005.xml\n",
      "g_006.xml----g_006.xml\n",
      "g_008.xml----g_008.xml\n",
      "g_009.xml----g_009.xml\n",
      "g_010.xml----g_010.xml\n",
      "g_011.xml----g_011.xml\n",
      "g_012.xml----g_012.xml\n",
      "h_001.xml----h_001.xml\n",
      "j_001.xml----j_001.xml\n",
      "l_001.xml----l_001.xml\n",
      "l_002.xml----l_002.xml\n",
      "m_001.xml----m_001.xml\n",
      "m_003.xml----m_003.xml\n",
      "m_004.xml----m_004.xml\n",
      "m_005.xml----m_005.xml\n",
      "m_006.xml----m_006.xml\n",
      "m_007.xml----m_007.xml\n",
      "m_008.xml----m_008.xml\n",
      "m_009.xml----m_009.xml\n",
      "m_010.xml----m_010.xml\n",
      "o_001.xml----o_001.xml\n",
      "o_002.xml----.xml\n",
      "p_001.xml----p_001.xml\n",
      "p_002.xml----p_002.xml\n",
      "p_003.xml----p_003.xml\n",
      "p_004.xml----p_004.xml\n",
      "r_001.xml----r_001.xml\n",
      "s_001.xml----s_001.xml\n",
      "s_002.xml----s_002.xml\n",
      "s_003.xml----s_003.xml\n",
      "s_004.xml----s_004.xml\n",
      "s_005.xml----s_005.xml\n",
      "s_006.xml----s_006.xml\n",
      "s_007.xml----s_007.xml\n",
      "t_001.xml----t_001.xml\n",
      "v_001.xml----v_001.xml\n",
      "v_002.xml----v_002.xml\n",
      "v_003.xml----v_003.xml\n",
      "v_004.xml----v_004.xml\n",
      "v_005.xml----v_005.xml\n",
      "va_001.xml----va_001.xml\n",
      "va_002.xml----va_002.xml\n",
      "va_003.xml----None.xml\n",
      "va_004.xml----va_004.xml\n",
      "va_006.xml----va_006.xml\n",
      "va_007.xml----va_007.xml\n",
      "va_008.xml----va_008.xml\n",
      "va_009.xml----va_009.xml\n",
      "va_010.xml----va_010.xml\n",
      "va_011.xml----va_011.xml\n",
      "va_012.xml----va_012.xml\n"
     ]
    }
   ],
   "source": [
    "# id_list is a list of the files which have a assigned period from the \n",
    "# periodos_tycho.csv file\n",
    "id_list = list(new_df.index)\n",
    "\n",
    "# the tycho_to_lda file is a file where each line corresponds to a\n",
    "# document from the corpus.\n",
    "with open('./corpora/tycho_to_lda', 'w') as dump:\n",
    "    for file_name, xml in forest.items():\n",
    "        \n",
    "        # get id\n",
    "        for i in xml:\n",
    "            if i.tag == 'head':\n",
    "                name = str(i.get('id'))+'.xml'\n",
    "        # Skipping files which don't have a period classification\n",
    "        # provided by the tycho_periods.csv\n",
    "        \n",
    "        if file_name[:-4] not in id_list:\n",
    "            print('not in id_lst= ',file_name)\n",
    "            continue\n",
    "        # get genre\n",
    "        genre = cm.get_meta('Genre',xml).xpath('string()')\n",
    "        new_df.loc[file_name[:-4],'genre'] = genre\n",
    "    \n",
    "        # get text\n",
    "        text = ' '.join(xml.xpath(\"//body//text()\"))\n",
    "        # process text and write to file\n",
    "        text = cm.pre_process(text)\n",
    "        dump.write(text)\n",
    "        dump.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "with open('./corpora/tycho_to_lda', 'r') as dump:\n",
    "    print(len(dump.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./corpora/tycho_to_lda_3.out', 'rb') as file:\n",
    "    lda_3 = pickle.load(file)\n",
    "\n",
    "lda_3.classifyDocuments()    \n",
    "\n",
    "df_3topics = new_df.copy()\n",
    "df_3topics['predicted_period'] = [lda_3.getDocTopic(i)[0] for i in range(len(new_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(df_3topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./corpora/tycho_to_lda_4.out', 'rb') as file:\n",
    "    lda_4 = pickle.load(file)\n",
    "\n",
    "lda_4.classifyDocuments()    \n",
    "\n",
    "df_4topics = new_df.copy()\n",
    "df_4topics['predicted_period'] = [lda_4.getDocTopic(i)[0] for i in range(len(new_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(df_4topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./corpora/tycho_to_lda_5.out', 'rb') as file:\n",
    "    lda_5 = pickle.load(file)\n",
    "\n",
    "lda_5.classifyDocuments()    \n",
    "\n",
    "df_5topics = new_df.copy()\n",
    "df_5topics['predicted_period'] = [lda_5.getDocTopic(i)[0] for i in range(len(new_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(df_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
