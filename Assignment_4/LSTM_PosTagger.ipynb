{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do\n",
    "\n",
    "[X] Load the data  \n",
    "[ ] Design the LSTM model  \n",
    "  \n",
    "    [X] Embedding layer. \n",
    "    [X] Linear Layer  \n",
    "[ X ] Train function  \n",
    "   \n",
    "    [X] Cross Entropy loss  \n",
    "    [X] Adam Optmizer  \n",
    "    \n",
    "[__] COMET\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "[  ] Tagging accuracy on a given sentence\n",
    "\n",
    "[  ] Accuracy on __Development__ Corpus after __each__ epoch\n",
    "\n",
    "[  ] Accuracy on __Trainning__ Corpus after __each__ epoch\n",
    "\n",
    "[  ] Accuracy on __Test__ Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/lflage/lstm-postagger/9548949d0273489eadde2c80936127aa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing comet first\n",
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(project_name=\"LSTM-PosTagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "##\n",
    "# Loading the corpus into the following variables\n",
    "#    train_dataloader           DataLoader for iterating over the training data\n",
    "#    dev_dataloader             DataLoader for iterating over the development data\n",
    "#    test_dataloader            DataLoader for iterating over the test data\n",
    "#    vocabulary                 Vocabulary of words in the sentences in the data\n",
    "#    tagset                     Vocabulary of POS tags in the data\n",
    "#    pretrained_embeddings      Pretrained fasttext word embeddings \n",
    "##\n",
    "\n",
    "train_dataloader,dev_dataloader,test_dataloader,vocabulary,tagset,pretrained_embeddings = data.load(\n",
    "'corpus/de_gsd-ud-train.conllu',\n",
    "'corpus/de_gsd-ud-dev.conllu',\n",
    "'corpus/de_gsd-ud-test.conllu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pretrained Embeddings shape:\n",
      "torch.Size([50506, 300])\n",
      "\n",
      "Tagset size:18\n",
      "\n",
      "Tags:\n",
      "['NOUN', 'PUNCT', 'DET', 'ADP', 'PROPN', 'VERB', 'ADJ', 'ADV', 'PRON', 'AUX', 'CCONJ', 'NUM', '_', 'PART', 'SCONJ', 'X', 'SYM', 'INTJ']\n",
      "\n",
      "Vocab size: 50506\n",
      "\n",
      "Vocab sample:\n",
      "['<unk>', '<pad>', '</s>', ',', 'der', 'die', 'in', 'und', 'dem', '-', 'von', 'zu', 'den', 'das', 'im', 'mit', 'ist', 'er', 'des', 'an', '\"', ')', '(', 'ein', 'eine', 'auf', 'als', 'f√ºr', 'sich', 'wurde', 'auch', 'war', 'nach', 'bei', 'sie', 'es', 'nicht', 'aus', 'bis', 'sind', 'einer', 'werden', 'zum', 'durch', 'wird', 'ich', 'am', 'einen', 'einem', 'zur']\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Print information of Embeddings, Tagset and Vocab\n",
    "##\n",
    "\n",
    "print(\"\\nPretrained Embeddings shape:\")\n",
    "print(pretrained_embeddings.shape)\n",
    "\n",
    "print(\"\\nTagset size:{}\\n\".format(len(tagset)))\n",
    "print('Tags:\\n{}'.format(tagset.lookup_tokens(range(0,len(tagset)))))\n",
    "\n",
    "print(\"\\nVocab size: {}\".format(len(vocabulary)))\n",
    "\n",
    "print(\"\\nVocab sample:\")\n",
    "print(vocabulary.lookup_tokens(range(0,50)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the batch Tensor objects: torch.Size([1, 2, 16])\n",
      "\n",
      "\n",
      "First POS Tags:\n",
      "\n",
      "ADV ADJ NOUN PUNCT ADJ NOUN DET NOUN PUNCT ADV VERB PRON PRON NOUN ADP PUNCT\n",
      "\n",
      "First Sentence:\n",
      "\n",
      "sehr gute beratung , schnelle behebung der probleme , so stelle ich mir kundenservice vor </s>\n"
     ]
    }
   ],
   "source": [
    "for minibatch in train_dataloader:\n",
    "\n",
    "    print('Shape of the batch Tensor objects: {}\\n'.format(minibatch.size()))\n",
    "    print('\\nFirst POS Tags:\\n')\n",
    "    print(' '.join(tagset.lookup_tokens(minibatch[0][1].flatten().tolist())))\n",
    "    print('\\nFirst Sentence:\\n')\n",
    "    print(' '.join(vocabulary.lookup_tokens(minibatch[0][0].flatten().tolist())))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPosTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "        embeddings,\n",
    "        hidden_dim,\n",
    "        tagset_size):\n",
    "        super(LSTMPosTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "\n",
    "        # The LSTM receives the word embedding vector a input and outputs\n",
    "        # a vector of size int(hidden_dim). This size can be changed to test\n",
    "        # it's influence on the model performance\n",
    "        self.lstm = nn.LSTM(self.word_embeddings.embedding_dim, hidden_dim)\n",
    "\n",
    "        # A Linear layer that receives the output of the LSTM model with\n",
    "        # size int(hidden_dim) and outputs a vector of size int(tagset_size) \n",
    "        self.hid_to_tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        '''sentence is a list of indices for the words in the pre trained embedding\n",
    "        model. Embeds '''\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        ''''''\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_scores = self.hid_to_tag(lstm_out.view(len(sentence), -1))\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_comet(model: Module, \n",
    "                train_data: DataLoader,\n",
    "                num_epochs: int,\n",
    "                optimizer_type,\n",
    "                loss_function,\n",
    "                learning_rate: float) -> None:\n",
    "    \"\"\"\n",
    "    runs one commplete training run, i.e. trains the model on your training data for\n",
    "    :param model: a pytorch model\n",
    "    :param train_data: a dataloader for getting the training instances\n",
    "    :param num_epochs: the number of epochs to train\n",
    "    :param optimizer_type: the type of optimizer to use for training\n",
    "    :param loss_function: the type of loss function to use\n",
    "    :param learning_rate: the learning rate for the optimizer\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(f'--------- Start Training ------------')\n",
    "\n",
    "    # Important: bring model into training mode\n",
    "    model.train()\n",
    "    experiment = Experiment()\n",
    "    \n",
    "    optimizer = optimizer_type(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # run training for specified number of epochs; use tqdm to keep track of progress / estimated run time \n",
    "    with experiment.train():\n",
    "        step=0\n",
    "\n",
    "        for epoch in tqdm(range(num_epochs), desc='Classifier Training\\n'):\n",
    "            # Cummulative loss per batch\n",
    "            cum_loss = 0\n",
    "            # Number of correct predictions\n",
    "            correct = 0\n",
    "            # Number of total tokens predicted\n",
    "            total = 0\n",
    "            \n",
    "            print(f'---------- Started Epoch {epoch} -----------')\n",
    "\n",
    "            for batch in train_data:\n",
    "                # get the input instances \n",
    "                input_attributes = batch[0][0].to(device)\n",
    "                # get the corresponding labels\n",
    "                gold_labels = batch[0][1].to(device)\n",
    "                \n",
    "                # compute model predictions with current model parameters\n",
    "                model_output = model(input_attributes)\n",
    "    \n",
    "                # Compute Loss for current batch\n",
    "                loss = loss_function(model_output, gold_labels)\n",
    "                cum_loss += loss.item()\n",
    "                  \n",
    "                #Important: otherwise you add up your gradients for all batches and for all epochs\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                loss.backward()\n",
    "    \n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "            \n",
    "                ##################################################\n",
    "                # COMET\n",
    "                # Compute train accuracy\n",
    "                # Torch.max returns a namedtuple where of (value,indices)\n",
    "                # where ```values``` is the maximum value of each rou of the\n",
    "                # input tensor in the given dimension \n",
    "                _, predicted = torch.max(model_output.data, 1)\n",
    "\n",
    "                batch_total = gold_labels.size(0)\n",
    "                total += batch_total\n",
    "\n",
    "                batch_correct = (predicted == gold_labels.data).sum()\n",
    "                correct += batch_correct\n",
    "\n",
    "                 # Log batch_accuracy to Comet.ml; step is each batch\n",
    "            step+=1\n",
    "            experiment.log_metric(\"mean_epoch_accuracy\", batch_correct / batch_total, step=step)\n",
    "                ################################################\n",
    "                \n",
    "            mean_loss_per_epoch = cum_loss/len(train_data)\n",
    "            experiment.log_metric('Mean_loss_per_epoch',mean_loss_per_epoch,step)\n",
    "            print(mean_loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "HIDDEN_SIZE = 300\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Inputs\n",
    "EMBEDDINGS = pretrained_embeddings\n",
    "\n",
    "OPTIMIZER = optim.Adam\n",
    "\n",
    "LOSS_FUNCTION = nn.functional.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperParameters = {'HiddenSize': HIDDEN_SIZE,\n",
    "                   'NumEpochs': NUM_EPOCHS,\n",
    "                   'LearningRate': LEARNING_RATE\n",
    "                  }\n",
    "\n",
    "experiment.log_parameters(HyperParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGGER = LSTMPosTagger(pretrained_embeddings,HIDDEN_SIZE,len(tagset))\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model on Development Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/lflage/general/e0f7f4bb701d46d4a8028fa08ffa4059\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (56 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Start Training ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/lflage/general/a81873a349a846f2ba14cb9516df5b0e\n",
      "\n",
      "\n",
      "\n",
      "Classifier Training\n",
      ":   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Epoch 0 -----------\n"
     ]
    }
   ],
   "source": [
    "train_model_comet(POS_TAGGER,\n",
    "            dev_dataloader,\n",
    "            NUM_EPOCHS,\n",
    "            OPTIMIZER,\n",
    "            LOSS_FUNCTION,\n",
    "            LEARNING_RATE)\n",
    "\n",
    "torch.save(POS_TAGGER.state_dict(),'./LSTM_PosTagger_DEV.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "\n",
    "torch.save(POS_TAGGER.state_dict(),'./LSTM_PosTagger_DEV.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    correct_predictions = 0\n",
    "    # iterate over each label and check\n",
    "    for true, predicted in zip(y_true, y_pred):\n",
    "        if true == predicted:\n",
    "            correct_predictions += 1\n",
    "    # compute the accuracy\n",
    "    accuracy = correct_predictions/len(y_true)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGGER.eval()\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_attributes = batch[0][0].to(device)\n",
    "    gold_labels = batch[0][1].to(device)\n",
    "    \n",
    "    model_output = POS_TAGGER(input_attributes)\n",
    "    \n",
    "    print(model_output.data)\n",
    "    print('\\n\\n\\nPREDICTED')\n",
    "    _, predicted = torch.max(model_output.data, 1)\n",
    "    print(predicted)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'POS_TAGGER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7495cd4a6069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS_TAGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPOS_TAGGER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'POS_TAGGER' is not defined"
     ]
    }
   ],
   "source": [
    "POS_TAGGER.eval()\n",
    "\n",
    "POS_TAGGER('')\n",
    "\n",
    "with experiment.test():\n",
    "    with torch.no_grad():  \n",
    "        correct=0\n",
    "        total=0\n",
    "           \n",
    "        test_predictions = None\n",
    "        test_targets = None\n",
    "        \n",
    "        for batch in test_dataloader:\n",
    "            print(f'--------- Evaluate Model ------------')\n",
    "            input_attributes = batch[0][0].to(device)\n",
    "            # get the corresponding labels\n",
    "            gold_labels = batch[0][1].to(device)\n",
    "\n",
    "            model_output = POS_TAGGER(input_attributes)\n",
    "            \n",
    "            print(gold_labels.size())\n",
    "            break\n",
    "\n",
    "        # run trained model on test instances\n",
    "\n",
    "        # compute evaluation metrics to evaluate the model performance based on predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGGER.eval()\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_attributes = batch[0][0].to(device)\n",
    "    gold_labels = batch[0][1].to(device)\n",
    "    \n",
    "    model_output = POS_TAGGER(input_attributes)\n",
    "    \n",
    "    print(model_output.data)\n",
    "    print('\\n\\n\\nPREDICTED')\n",
    "    _, predicted = torch.max(model_output.data, 1)\n",
    "    print(predicted)\n",
    "    print( '\\n\\n\\nGOLD LABEL SIZE:')\n",
    "    print(gold_labels.size())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
