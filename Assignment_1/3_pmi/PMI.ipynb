{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5853a1ad",
   "metadata": {},
   "source": [
    "# PMI\n",
    "\n",
    "The first step taken for this exercise was to treat the corpus, the Jungle Book, as a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "296e67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2a7b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../corpora/tokenized/junglebook_tokenized.txt') as jb_tk:\n",
    "    jb_list = []\n",
    "    for line in jb_tk.readlines():\n",
    "        jb_list.extend(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846a754",
   "metadata": {},
   "source": [
    "### Unigram Occurences\n",
    "Now we use the Counter dict to obtain the occurences for each word. We list the top 10 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cdb0b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3695), ('and', 2321), ('of', 1347), ('to', 1261), ('a', 1147), ('he', 1071), ('in', 742), ('his', 659), ('that', 659), ('i', 580)]\n"
     ]
    }
   ],
   "source": [
    "uni_count = Counter(jb_list)\n",
    "print(sorted(uni_count.items(),key=lambda x:x[1],reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8568a3",
   "metadata": {},
   "source": [
    "We create a list of the less frequent values by first using dict comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2cdad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_freq = list({key:uni_count[key] for key in uni_count if uni_count[key]<10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2bc1f",
   "metadata": {},
   "source": [
    "Then we remove the less frequent values from the jb_list variable using list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e06eb2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43980\n"
     ]
    }
   ],
   "source": [
    "jb_list_filtered = [token for token in jb_list if token not in less_freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cb675",
   "metadata": {},
   "source": [
    "We now create tuples from the word pairs [i-1] and [i] and store them in a list.Afterwards we create another Counter dict to store the occurances of these tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7ac58d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting \n",
    "list_of_tup = []\n",
    "for i in range(len(jb_list_filtered)):\n",
    "    list_of_tup.append((jb_list_filtered[i-1],jb_list_filtered[i]))\n",
    "\n",
    "del list_of_tup[0] # removes the tuple generated from the first and last token([-1],[0]).\n",
    "\n",
    "# \n",
    "bi_count = Counter(list_of_tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9d2e1",
   "metadata": {},
   "source": [
    "We than calculate the **PMI** for each word pair in the previously defined Counter object ```bi_count``` and store them in dictionary, where the key is the word pair and the value is the PMI value for this word pair. In the next cell we see an example of the acessed iterable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d7d8b976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'project'), 36)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bi_count.items())[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42017e3c",
   "metadata": {},
   "source": [
    "To obtain the **PMI** value we use the lenght of the list ```jb_list_filtered``` as the size of the corpus, and we acess the absolute frequency of the word pairs in index 1 of the item **```i```**. The absolute frequencies of the words alone in the corpus is acessed through the ```uni_count``` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8a5ae899",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_values = {}\n",
    "\n",
    "for i in bi_count.items():\n",
    "    pmi = math.log((i[1] * len(jb_list_filtered))/(uni_count[i[0][0]]*uni_count[i[0][1]]))\n",
    "    pmi_values[i[0]] = pmi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71847b4d",
   "metadata": {},
   "source": [
    "The values are then sorted using the ```sorted()``` built in function, giving us a list tuples, in which we have the word pair in the tuple's index 0 and it's **PMI** value in index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7be511f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pmi_values = sorted(pmi_values.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73f475",
   "metadata": {},
   "source": [
    "To estabilish what a 0, or near 0, **PMI** would look like, the values of PMI in the range [-0.01, 0.01] where stored in a list and some of them are shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "02d49a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "[('can', 'with'), ('page', 'the'), ('forget', 'the'), ('the', 'wonderful'), ('perhaps', 'the'), ('the', 'jump'), ('tree', 'the'), ('quickly', 'the'), ('high', 'the'), ('makes', 'the')]\n"
     ]
    }
   ],
   "source": [
    "near_zero_pmi = [word_pair for word_pair, pmi in sorted_pmi_values if pmi>-0.01 and pmi<0.01]\n",
    "print(len(near_zero_pmi))\n",
    "print(near_zero_pmi[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d294aa",
   "metadata": {},
   "source": [
    "## The highest and lowest PMI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "62aa8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word pair('council', 'rock')\t\t\tpmi value = 6.5018355220823265\n",
      "Word pair('mans', 'cub')\t\t\tpmi value = 6.603224747963034\n",
      "Word pair('bring', 'news')\t\t\tpmi value = 6.61961855773871\n",
      "Word pair('years', 'ago')\t\t\tpmi value = 6.637967696406907\n",
      "Word pair('master', 'words')\t\t\tpmi value = 6.666138573373603\n",
      "Word pair('hind', 'flippers')\t\t\tpmi value = 6.684157078876281\n",
      "Word pair('electronic', 'works')\t\t\tpmi value = 6.702506217544478\n",
      "Word pair('whole', 'line')\t\t\tpmi value = 6.714928737543035\n",
      "Word pair('twenty', 'yoke')\t\t\tpmi value = 6.8466760083740565\n",
      "Word pair('fore', 'paws')\t\t\tpmi value = 6.907300630190491\n",
      "Word pair('hind', 'legs')\t\t\tpmi value = 6.984911232895415\n",
      "Word pair('petersen', 'sahib')\t\t\tpmi value = 7.127484139876224\n",
      "Word pair('stretched', 'myself')\t\t\tpmi value = 7.184932366788771\n",
      "Word pair('gutenberg', 'literary')\t\t\tpmi value = 7.290292882446597\n",
      "Word pair('cold', 'lairs')\t\t\tpmi value = 7.501601976113804\n",
      "Word pair('archive', 'foundation')\t\t\tpmi value = 7.6004478107504365\n",
      "Word pair('darzees', 'wife')\t\t\tpmi value = 7.695757990554761\n",
      "Word pair('united', 'states')\t\t\tpmi value = 7.983440063006542\n",
      "Word pair('literary', 'archive')\t\t\tpmi value = 8.126540906647215\n",
      "Word pair('machua', 'appa')\t\t\tpmi value = 8.28354465545688\n"
     ]
    }
   ],
   "source": [
    "for word_pair, value in sorted_pmi_values[-20:]:\n",
    "    print('Word pair{0}'.format(word_pair)+'\\t\\t\\t'+ 'pmi value = {0}'.format(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "15053c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word pair('he', 'of')\t\t\tpmi value = -3.4904929827493607\n",
      "Word pair('his', 'the')\t\t\tpmi value = -3.320821923216112\n",
      "Word pair('the', 'not')\t\t\tpmi value = -3.2435573458809617\n",
      "Word pair('little', 'the')\t\t\tpmi value = -3.0038844926155415\n",
      "Word pair('the', 'a')\t\t\tpmi value = -2.9587127739688204\n",
      "Word pair('the', 'be')\t\t\tpmi value = -2.851121738063131\n",
      "Word pair('a', 'his')\t\t\tpmi value = -2.8441383875231256\n",
      "Word pair('of', 'was')\t\t\tpmi value = -2.7945407512618066\n",
      "Word pair('said', 'of')\t\t\tpmi value = -2.60545479437931\n",
      "Word pair('he', 'he')\t\t\tpmi value = -2.5680586962268\n",
      "Word pair('the', 'no')\t\t\tpmi value = -2.533880863369806\n",
      "Word pair('in', 'in')\t\t\tpmi value = -2.5272082222260086\n",
      "Word pair('and', 'is')\t\t\tpmi value = -2.4897993524999444\n",
      "Word pair('a', 'the')\t\t\tpmi value = -2.4887091447230847\n",
      "Word pair('the', 'if')\t\t\tpmi value = -2.4720054596517183\n",
      "Word pair('very', 'the')\t\t\tpmi value = -2.4504992544307544\n",
      "Word pair('they', 'of')\t\t\tpmi value = -2.4490391079211995\n",
      "Word pair('of', 'they')\t\t\tpmi value = -2.4490391079211995\n",
      "Word pair('to', 'they')\t\t\tpmi value = -2.383064267475755\n",
      "Word pair('do', 'the')\t\t\tpmi value = -2.383057973635222\n"
     ]
    }
   ],
   "source": [
    "for word_pair, value in sorted_pmi_values[:20]:\n",
    "    print('Word pair{0}'.format(word_pair)+'\\t\\t\\t'+ 'pmi value = {0}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0e641",
   "metadata": {},
   "source": [
    "# Analyzing the Results\n",
    "\n",
    "The top 20 results with the highest PMI are bigrams, or word pairs, which seem semantically plausible. We have, for example, the pair (\"united\",\"states\"), which indicates the country, and the pair ('council', 'rock'), which is a location from the book. We also see words from certain parts of speech, such as nouns (wife, legs,paws), adverbs (eletronic, fore) and some propper collocations (('years','ago'), ('bring','news').\n",
    "\n",
    "On the other hand the top 20 results with the lowest PMI show mostly prepositions(at, int, of), determinants (a, the) and pronouns (he, his, they). Those are the words which have a high absolute frequency, but a small likelihood to occuring in pairs.\n",
    "\n",
    "Using such a qualitative and quantiative analysis we are able to infer that in natural occuring texts, there is a dependency relation between one word and the word that occurs next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
