{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8534c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from nltk.grammar import *\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6c7c3",
   "metadata": {},
   "source": [
    "# Loading the Corpus and Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce19994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the ATIS CNF grammar and the sentences. If the sentences file is not available,\n",
    "# automatically downloads it and loads it\n",
    "\n",
    "try:\n",
    "    grammar = nltk.data.load('atis/atis-grammar-cnf.cfg')\n",
    "    s = nltk.data.load('grammars/large_grammars/atis_sentences.txt')\n",
    "    t = nltk.parse.util.extract_test_sentences(s)\n",
    "    \n",
    "except LookupError:\n",
    "    nltk.download('large_grammars')\n",
    "    \n",
    "    grammar = nltk.data.load('atis/atis-grammar-cnf.cfg')\n",
    "    s = nltk.data.load('grammars/large_grammars/atis_sentences.txt')\n",
    "    t = nltk.parse.util.extract_test_sentences(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b045767",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('atis/atis-grammar-cnf.cfg','r') as string_cfg:\n",
    "    grammar1 = nltk.grammar.CFG.fromstring(string_cfg.read())\n",
    "grammar1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6a879",
   "metadata": {},
   "source": [
    "## Test Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cbff4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " NP -> Det N,\n",
       " NP -> NP PP,\n",
       " PP -> P NP,\n",
       " VP -> V NP,\n",
       " VP -> VP PP,\n",
       " NP -> 'I',\n",
       " N -> 'elephant',\n",
       " N -> 'pajamas',\n",
       " V -> 'shot',\n",
       " P -> 'in',\n",
       " Det -> 'an',\n",
       " Det -> 'my']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_grammar_string = '''\n",
    "S -> NP VP\n",
    "NP -> Det N\n",
    "NP -> NP PP\n",
    "PP -> P NP\n",
    "VP -> V NP\n",
    "VP -> VP PP\n",
    "\n",
    "NP -> 'I'\n",
    "N -> 'elephant'\n",
    "N -> 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "Det -> 'an'\n",
    "Det -> 'my'\n",
    "'''\n",
    "\n",
    "test_grammar = nltk.grammar.CFG.fromstring(test_grammar_string)\n",
    "test_grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the grammar productions, filtered by the left-hand side\n",
    "# or the first item in the right-hand side.\n",
    "for prod in grammar1.productions(lhs=Nonterminal('order')):\n",
    "    print(prod)\n",
    "rule = grammar1.productions(lhs=Nonterminal('NP'),rhs=Nonterminal('VP'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556f969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NP VP, NP -> NP PP]\n"
     ]
    }
   ],
   "source": [
    "#print(test_grammar.productions(rhs=Nonterminal('elephant')))\n",
    "\n",
    "print(test_grammar.productions(rhs=Nonterminal('NP')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8c111a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKY:\n",
    "    def __init__(self,sentence, grammar):\n",
    "        self.grammar = grammar\n",
    "        self.sent_list = sentence.split()\n",
    "        n = len(self.sent_list)\n",
    "        \n",
    "        self.chart = [[None for i in range(n)] for j in range(n)]\n",
    "        \n",
    "        \n",
    "        for i in range(1, n+1):\n",
    "            # Adds all possible terminal nodes according to the grammar\n",
    "            self.chart[n-i][i-1] = [rule.lhs()\n",
    "                            for rule in self.grammar.productions(rhs=self.sent_list[i-1])]\n",
    "            \n",
    "        for b in range(2, n+1):\n",
    "            for i in range(0, n-b+1):\n",
    "                list_of_As = []\n",
    "                for k in range(1, b):\n",
    "                    B = self.chart[n-i-k][i]\n",
    "                    C = self.chart[n-b-i][i + k]\n",
    "                    if B and C:\n",
    "                        # If B and C exist then compare them. Saves checking\n",
    "                        # every possible k point\n",
    "                        list_of_As.append(CKY.check_grammar(\n",
    "                            self.grammar,B,C))\n",
    "                        #self.chart[n-b-i][i] = CKY.check_grammar(\n",
    "                        #    self.grammar,B,C)\n",
    "                    else:\n",
    "                        continue                \n",
    "                self.chart[n-b-i][i] = list(filter(None,list_of_As))\n",
    "\n",
    "                \n",
    "    \n",
    "    def check_grammar(gram, B,C):\n",
    "        # param B: list of all possible elements for rhs right corner\n",
    "        # param C: list of all possible elements for rhs left corner\n",
    "        # return A: list of all possible elements for lhs\n",
    "        \n",
    "        # B = B.rhs()[0]\n",
    "        for element_B in B:\n",
    "            # for every production with element_B on the left side of the\n",
    "            # righ hand side, check if there is a production with element_C\n",
    "            # on the right side of right hand side\n",
    "            \n",
    "            for prod in gram.productions(rhs=element_B):\n",
    "                for element_C in C:\n",
    "                    if prod.rhs() == (element_B, element_C):\n",
    "                        return(prod.lhs())\n",
    "\n",
    "    \n",
    "    def print_chart(self):\n",
    "        pprint(chart)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4ca5fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP\n",
      "NP\n",
      "VP\n",
      "PP\n",
      "S\n",
      "NP\n",
      "VP\n",
      "VP\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "racog = CKY('I shot an elephant in my pajamas', test_grammar)\n",
    "#pprint(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4f1721c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.grammar.Nonterminal'>\n"
     ]
    }
   ],
   "source": [
    "print(type(racog.chart[0][0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "090e6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.grammar.Nonterminal'>\n",
      "VP\n",
      "piru\n",
      "<class 'nltk.grammar.Production'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_grammar.productions()[0].rhs()[1]))\n",
    "print(test_grammar.productions()[0].rhs()[1])\n",
    "if test_grammar.productions()[0].rhs() == (Nonterminal('NP'),Nonterminal('VP')):\n",
    "    print('piru')\n",
    "print(type(test_grammar.productions()[0]))\n",
    "prod = test_grammar.productions()[0]\n",
    "\n",
    "?prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9ebd0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[NP, V, TESTE, Det, N, P, Det, N],\n",
      "  [V, TESTE, Det, N, P, Det, N],\n",
      "  [Det, N, P, Det, N],\n",
      "  [N, P, Det, N],\n",
      "  [P, Det, N],\n",
      "  [Det, N],\n",
      "  [N]],\n",
      " [[NP, V, TESTE, Det, N, P, Det],\n",
      "  [V, TESTE, Det, N, P, Det],\n",
      "  [Det, N, P, Det],\n",
      "  [N, P, Det],\n",
      "  [P, Det],\n",
      "  [Det],\n",
      "  0],\n",
      " [[NP, V, TESTE, Det, N, P],\n",
      "  [V, TESTE, Det, N, P],\n",
      "  [Det, N, P],\n",
      "  [N, P],\n",
      "  [P],\n",
      "  0,\n",
      "  0],\n",
      " [[NP, V, TESTE, Det, N], [V, TESTE, Det, N], [Det, N], [N], 0, 0, 0],\n",
      " [[NP, V, TESTE, Det], [V, TESTE, Det], [Det], 0, 0, 0, 0],\n",
      " [[NP, V, TESTE], [V, TESTE], 0, 0, 0, 0, 0],\n",
      " [[NP], 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# def CKY_recognizer(sentence, grammar):\n",
    "#     sent_list = sentence.split()\n",
    "#     n = len(sent_list)\n",
    "#     # Initializes the matrix with 'None' types\n",
    "#     matrix = [[None for i in range(n)] for j in range(n)]\n",
    "\n",
    "#     for i in range(1, n+1):\n",
    "#         # Adds all possible terminal nodes according to the grammar\n",
    "        \n",
    "#         matrix[n-i][i-1] = [rule.lhs()\n",
    "#                             for rule in grammar.productions(rhs=sent_list[i-1])]\n",
    "\n",
    "#     for b in range(2, n+1):\n",
    "#         for i in range(0, n-b+1):\n",
    "#             # matrix [n-b-i][i]\n",
    "#             # row = n-b-i\n",
    "#             # column = i\n",
    "            \n",
    "#             # A = matrix[row][column]\n",
    "            \n",
    "#             for k in range(1, b):\n",
    "#                 B = matrix[n-i-k][i]\n",
    "#                 C = matrix[n-b-i][i + k]\n",
    "#                 A = B + C\n",
    "                \n",
    "#                 if B and C:\n",
    "#                     matrix[row][column] = check_grammar(B,C)\n",
    "#                     # If B and C exist then compare them. Saves checking\n",
    "#                     # every possible k point\n",
    "#                     matrix[n-b-i][i] = B + C\n",
    "                    \n",
    "#                     # B: list of all possible rhs (right leaf) \n",
    "#                     # C: list of all possible rhs (left leaf)\n",
    "#                     # is there a rule which has B and C as leave\n",
    "#                 else:\n",
    "#                     continue\n",
    "                \n",
    "#                 print('B =', B)\n",
    "#                 print('C =', C)\n",
    "#                 if input(''):\n",
    "#                     pass\n",
    "#             pprint(matrix)\n",
    "#             print('\\n')\n",
    "                \n",
    "#     return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7472d76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c33183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670dd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
